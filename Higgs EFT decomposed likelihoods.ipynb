{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "\n",
    "import os, sys, inspect\n",
    "cmd_folder = os.path.realpath(os.path.abspath(os.path.split(inspect.getfile( inspect.currentframe() ))[0]))\n",
    "if cmd_folder not in sys.path:\n",
    "    sys.path.insert(0, cmd_folder + '/carl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = [[1.0, -0.5, -0.5], \n",
    "         [1.0, -0.5, 0.5], \n",
    "         [1.0, -0.35714285714285715, -0.071428571428571452], \n",
    "         [1.0, -0.35714285714285715, 0.21428571428571419], \n",
    "         [1.0, -0.2142857142857143, -0.2142857142857143], \n",
    "         [1.0, -0.2142857142857143, 0.071428571428571397], \n",
    "         [1.0, -0.2142857142857143, 0.3571428571428571], \n",
    "         [1.0, -0.071428571428571452, -0.35714285714285715], \n",
    "         [1.0, -0.071428571428571452, -0.071428571428571452], \n",
    "         [1.0, -0.071428571428571452, 0.21428571428571419], \n",
    "         [1.0, 0.21428571428571419, -0.2142857142857143], \n",
    "         [1.0, 0.21428571428571419, 0.071428571428571397], \n",
    "         [1.0, 0.3571428571428571, 0.5], \n",
    "         [1.0, 0.5, -0.071428571428571452], \n",
    "         [1.0, 0.5, 0.21428571428571419],\n",
    "         [1.0, -0.5, -0.35714285714285715], \n",
    "         [1.0, -0.5, -0.071428571428571452], \n",
    "         [1.0, -0.5, 0.3571428571428571], \n",
    "         [1.0, -0.2142857142857143, -0.071428571428571452], \n",
    "         [1.0, -0.2142857142857143, 0.21428571428571419], \n",
    "         [1.0, -0.2142857142857143, 0.5], \n",
    "         [1.0, -0.071428571428571452, -0.5], \n",
    "         [1.0, -0.071428571428571452, -0.2142857142857143], \n",
    "         [1.0, -0.071428571428571452, 0.071428571428571397], \n",
    "         [1.0, 0.071428571428571397, -0.071428571428571452], \n",
    "         [1.0, 0.071428571428571397, 0.3571428571428571], \n",
    "         [1.0, 0.21428571428571419, -0.35714285714285715], \n",
    "         [1.0, 0.21428571428571419, 0.21428571428571419], \n",
    "         [1.0, 0.5, -0.2142857142857143], \n",
    "         [1.0, 0.5, 0.5]]\n",
    "\n",
    "theta = np.array(theta)\n",
    "\n",
    "theta_0 = theta[:15]\n",
    "theta_1 = theta[15:]\n",
    "\n",
    "F1 = [1.0, 0.0, 0.0]\n",
    "F0 = theta_0[0]\n",
    "\n",
    "feature_names = [\"minDelR_jZ\", \"DelPhi_Hjj\", \"DelEta_Hjj\", \"DelPhi_jj\", \"DelR_jj\", \n",
    "                 \"DelY_jj\", \"Mjj\", \"DelPt_jj\", \"DelPt_ZZ\", \"pT_Hjj\", \"Mjets\", \"Zeppetaj3\", \n",
    "                 \"ZeppetaZZ\", \"njets\",\"Z1_E\",\"Z1_pt\",\"Z1_eta\",\"Z1_phi\",\"Z1_m\",\"Z2_E\",\"Z2_pt\",\n",
    "                 \"Z2_eta\",\"Z2_phi\",\"Z2_m\",  \"higgs_E\",\"higgs_pt\",\"higgs_eta\",\"higgs_phi\",\"higgs_m\", \n",
    "                 \"jet1_E\",\"jet1_eta\",\"jet1_y\",\"jet1_phi\",\"jet1_pt\",\"jet1_m\",\"jet2_E\", \"jet2_eta\",\"jet2_y\", \n",
    "                 \"jet2_phi\",\"jet2_pt\",\"jet2_m\",\"jet3_E\",\"jet3_eta\",\"jet3_y\" ,\"jet3_phi\",\"jet3_pt\",\"jet3_m\"]\n",
    "\n",
    "subset = [33, 3] #DelPhi_jj, jet1_pt\n",
    "observed = 'F1'\n",
    "data_F0 = 0\n",
    "\n",
    "c_min = [-0.3557, -0.34467]\n",
    "#c_min = [-0.1,-0.1]\n",
    "c_max = [0.2646, 0.34467]\n",
    "npoints = 15\n",
    "\n",
    "n_samples = 40000\n",
    "test_samples = 15000\n",
    "\n",
    "# subset = list(range(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_observed = np.loadtxt(\"/afs/cern.ch/work/j/jpavezse/private/data/new_data/data_%s.dat\" \n",
    "                        % observed)[:test_samples, subset]\n",
    "X_observed.shape\n",
    "\n",
    "# ideally, X_observed should be an independent sample not used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"/afs/cern.ch/work/j/jpavezse/private/data/new_data\"\n",
    "# Mixture Model\n",
    "class Component:\n",
    "    def __init__(self, base):\n",
    "        self.data = np.loadtxt(\"%s/data_%d.dat\" % (data_dir,base))[:, subset]\n",
    "    def rvs(self, n_samples, random_state=1234):\n",
    "        n_samples = n_samples if n_samples < len(self.data) else len(self.data)\n",
    "        return self.data[:n_samples]\n",
    "    \n",
    "class Mixture:\n",
    "    def __init__(self, basis, couplings, cross_sections):\n",
    "        self.basis = basis\n",
    "        self.couplings = couplings\n",
    "        self.cross_sections = cross_sections\n",
    "        self.components = []\n",
    "        for base in self.basis:\n",
    "            self.components.append(Component(base))\n",
    "    \n",
    "    def compute_weights(self,**kwargs):\n",
    "        couplings = np.array(map(lambda x: x.eval(),self.couplings))\n",
    "        cross_sections = np.array(map(lambda x: x.eval(), self.cross_sections))\n",
    "        cs = np.multiply(couplings, cross_sections)\n",
    "        return cs / cs.sum()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading indexes, couplings and cross_sections\n",
    "all_indexes = np.loadtxt(\n",
    "    'doubleindexes_{0:.2f}_{1:.2f}_{2:.2f}_{3:.2f}_{4}.dat'.format(\n",
    "        c_min[0], c_min[1], c_max[0], c_max[1], npoints))\n",
    "all_indexes = np.array([[int(x) for x in rows]\n",
    "                        for rows in all_indexes])\n",
    "all_couplings = np.loadtxt(\n",
    "    'doublecouplings_{0:.2f}_{1:.2f}_{2:.2f}_{3:.2f}_{4}.dat'.format(\n",
    "        c_min[0], c_min[1], c_max[0], c_max[1], npoints))\n",
    "all_cross_sections = np.loadtxt(\n",
    "    'doublecrosssection_{0:.2f}_{1:.2f}_{2:.2f}_{3:.2f}_{4}.dat'.format(\n",
    "        c_min[0], c_min[1], c_max[0], c_max[1], npoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define Mixture Models\n",
    "base_mixtures = []\n",
    "couplings = []\n",
    "cross_sections = []\n",
    "for b, indexes in enumerate(all_indexes):\n",
    "    couplings.append([theano.shared(0.,name='w_{0}_{1}'.format(b,k)) for k in range(len(indexes))])\n",
    "    cross_sections.append([theano.shared(0.,name='cx_{0}_{1}'.format(b,k)) for k in range(len(indexes))])\n",
    "    base_mixtures.append(Mixture(indexes, couplings[b], cross_sections[b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For denominator using just the first component\n",
    "den_indexes = [data_F0]\n",
    "den_couplings = [theano.shared(1.,name='w_den')]\n",
    "den_cross_sections = [theano.shared(1., name='cx_den')]\n",
    "den_mixture = Mixture(den_indexes, den_couplings, den_cross_sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csarray_0 = np.linspace(c_min[0], c_max[0], npoints)\n",
    "csarray_1 = np.linspace(c_min[1], c_max[1], npoints)\n",
    "decomposedLikelihood = np.zeros((npoints, npoints))\n",
    "n_effs = np.zeros((npoints, npoints))\n",
    "alphas = np.zeros((2, npoints, npoints))\n",
    "ratiosList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from carl.ratios import ClassifierRatio\n",
    "from carl.ratios import DecomposedRatio\n",
    "from carl.learning import CalibratedClassifierCV\n",
    "\n",
    "from carl.ratios import ClassifierRatio\n",
    "from carl.learning import CalibratedClassifierCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def make_ratio(num, den):\n",
    "    clf = ExtraTreesClassifier(n_estimators=100, min_samples_split=20, random_state=0, n_jobs=-1)\n",
    "    cv =  StratifiedShuffleSplit(n_iter=3, test_size=0.5, random_state=1)\n",
    "\n",
    "    ratio = DecomposedRatio(ClassifierRatio(\n",
    "        base_estimator=CalibratedClassifierCV(clf, cv=cv, bins=25),\n",
    "        random_state=0))\n",
    "    ratio.fit(numerator=num, denominator=den, n_samples=n_samples)\n",
    "    \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_ratios = []\n",
    "base_ratios.append(make_ratio(base_mixtures[0],den_mixture))\n",
    "base_ratios.append(make_ratio(base_mixtures[1],den_mixture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weights(w):\n",
    "    n_tot = np.abs(w).sum()\n",
    "    n_eff = w.sum()\n",
    "    n_eff = n_eff / n_tot\n",
    "    alpha = np.exp(-np.sqrt(1./n_eff))\n",
    "    #alpha1 = np.exp(-neff1**(1./3.))\n",
    "    return alpha, n_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "(1, 0, (96,))\n",
      "0 1\n",
      "(1, 0, (98,))\n",
      "0 2\n",
      "(1, 0, (112,))\n",
      "0 3\n",
      "(1, 0, (76,))\n",
      "0 4\n",
      "(1, 0, (32,))\n",
      "0 5\n",
      "(1, 0, (5,))\n",
      "0 6\n",
      "(1, 0, (1,))\n",
      "0 7\n",
      "(1, 0, (14,))\n",
      "0 8\n",
      "(1, 0, (18,))\n",
      "0 9\n",
      "(1, 0, (18,))\n",
      "0 10\n",
      "(1, 0, (15,))\n",
      "0 11\n",
      "(1, 0, (11,))\n",
      "0 12\n",
      "(1, 0, (54,))\n",
      "0 13\n",
      "(1, 0, (88,))\n",
      "0 14\n",
      "(1, 0, (79,))\n",
      "1 0\n",
      "(1, 0, (105,))\n",
      "1 1\n",
      "(1, 0, (46,))\n",
      "1 2\n",
      "(1, 0, (47,))\n",
      "1 3\n",
      "(1, 0, (33,))\n",
      "1 4\n",
      "(1, 0, (22,))\n",
      "1 5\n",
      "(1, 0, (2,))\n",
      "1 6\n",
      "(1, 0, (0,))\n",
      "1 7\n",
      "(1, 0, (4,))\n",
      "1 8\n",
      "(1, 0, (6,))\n",
      "1 9\n",
      "(1, 0, (0,))\n",
      "1 10\n",
      "(1, 0, (0,))\n",
      "1 11\n",
      "(1, 0, (16,))\n",
      "1 12\n",
      "(1, 0, (68,))\n",
      "1 13\n",
      "(1, 0, (83,))\n",
      "1 14\n",
      "(1, 0, (68,))\n",
      "2 0\n",
      "(1, 0, (96,))\n",
      "2 1\n",
      "(1, 0, (6,))\n",
      "2 2\n",
      "(1, 0, (0,))\n",
      "2 3\n",
      "(1, 0, (1,))\n",
      "2 4\n",
      "(1, 0, (0,))\n",
      "2 5\n",
      "(1, 0, (0,))\n",
      "2 6\n",
      "(1, 0, (0,))\n",
      "2 7\n",
      "(1, 0, (0,))\n",
      "2 8\n",
      "(1, 0, (0,))\n",
      "2 9\n",
      "(1, 0, (0,))\n",
      "2 10\n",
      "(1, 0, (2,))\n",
      "2 11\n",
      "(1, 0, (15,))\n",
      "2 12\n",
      "(1, 0, (18,))\n",
      "2 13\n",
      "(1, 0, (28,))\n",
      "2 14\n",
      "(1, 0, (20,))\n",
      "3 0\n",
      "(1, 0, (28,))\n",
      "3 1\n",
      "(1, 0, (0,))\n",
      "3 2\n",
      "(1, 0, (0,))\n",
      "3 3\n",
      "(1, 0, (0,))\n",
      "3 4\n",
      "(1, 0, (0,))\n",
      "3 5\n",
      "(1, 0, (0,))\n",
      "3 6\n",
      "(1, 0, (0,))\n",
      "3 7\n",
      "(1, 0, (0,))\n",
      "3 8\n",
      "(1, 0, (0,))\n",
      "3 9\n",
      "(1, 0, (0,))\n",
      "3 10\n",
      "(1, 0, (2,))\n",
      "3 11\n",
      "(1, 0, (3,))\n",
      "3 12\n",
      "(1, 0, (5,))\n",
      "3 13\n",
      "(1, 0, (6,))\n",
      "3 14\n",
      "(1, 0, (0,))\n",
      "4 0\n",
      "(1, 0, (17,))\n",
      "4 1\n",
      "(1, 0, (0,))\n",
      "4 2\n",
      "(1, 0, (0,))\n",
      "4 3\n",
      "(1, 0, (0,))\n",
      "4 4\n",
      "(1, 0, (0,))\n",
      "4 5\n",
      "(1, 0, (0,))\n",
      "4 6\n",
      "(1, 0, (0,))\n",
      "4 7\n",
      "(1, 0, (0,))\n",
      "4 8\n",
      "(1, 0, (0,))\n",
      "4 9\n",
      "(1, 0, (0,))\n",
      "4 10\n",
      "(1, 0, (0,))\n",
      "4 11\n",
      "(1, 0, (0,))\n",
      "4 12\n",
      "(1, 0, (0,))\n",
      "4 13\n",
      "(1, 0, (0,))\n",
      "4 14\n",
      "(1, 0, (0,))\n",
      "5 0\n",
      "(1, 0, (0,))\n",
      "5 1\n",
      "(1, 0, (0,))\n",
      "5 2\n",
      "(1, 0, (0,))\n",
      "5 3\n",
      "(1, 0, (0,))\n",
      "5 4\n",
      "(1, 0, (0,))\n",
      "5 5\n",
      "(1, 0, (0,))\n",
      "5 6\n",
      "(1, 0, (0,))\n",
      "5 7\n",
      "(1, 0, (0,))\n",
      "5 8\n",
      "(1, 0, (0,))\n",
      "5 9\n",
      "(1, 0, (0,))\n",
      "5 10\n",
      "(1, 0, (0,))\n",
      "5 11\n",
      "(1, 0, (0,))\n",
      "5 12\n",
      "(1, 0, (0,))\n",
      "5 13\n",
      "(1, 0, (0,))\n",
      "5 14\n",
      "(1, 0, (9,))\n",
      "6 0\n",
      "(1, 0, (0,))\n",
      "6 1\n",
      "(1, 0, (0,))\n",
      "6 2\n",
      "(1, 0, (0,))\n",
      "6 3\n",
      "(1, 0, (0,))\n",
      "6 4\n",
      "(1, 0, (0,))\n",
      "6 5\n",
      "(1, 0, (0,))\n",
      "6 6\n",
      "(1, 0, (1,))\n",
      "6 7\n",
      "(1, 0, (2,))\n",
      "6 8\n",
      "(1, 0, (0,))\n",
      "6 9\n",
      "(1, 0, (0,))\n",
      "6 10\n",
      "(1, 0, (0,))\n",
      "6 11\n",
      "(1, 0, (0,))\n",
      "6 12\n",
      "(1, 0, (0,))\n",
      "6 13\n",
      "(1, 0, (8,))\n",
      "6 14\n",
      "(1, 0, (12,))\n",
      "7 0\n",
      "(1, 0, (0,))\n",
      "7 1\n",
      "(1, 0, (2,))\n",
      "7 2\n",
      "(1, 0, (0,))\n",
      "7 3\n",
      "(1, 0, (0,))\n",
      "7 4\n",
      "(1, 0, (1,))\n",
      "7 5\n",
      "(1, 0, (1,))\n",
      "7 6\n",
      "(1, 0, (27,))\n",
      "7 7\n",
      "(1, 0, (25,))\n",
      "7 8\n",
      "(1, 0, (6,))\n",
      "7 9\n",
      "(1, 0, (3,))\n",
      "7 10\n",
      "(1, 0, (2,))\n",
      "7 11\n",
      "(1, 0, (0,))\n",
      "7 12\n",
      "(1, 0, (2,))\n",
      "7 13\n",
      "(1, 0, (11,))\n",
      "7 14\n",
      "(1, 0, (14,))\n",
      "8 0\n",
      "(1, 0, (7,))\n",
      "8 1\n",
      "(1, 0, (7,))\n",
      "8 2\n",
      "(1, 0, (7,))\n",
      "8 3\n",
      "(1, 0, (0,))\n",
      "8 4\n",
      "(1, 0, (1,))\n",
      "8 5\n",
      "(1, 0, (1,))\n",
      "8 6\n",
      "(1, 0, (13,))\n",
      "8 7\n",
      "(1, 0, (11,))\n",
      "8 8\n",
      "(1, 0, (7,))\n",
      "8 9\n",
      "(1, 0, (5,))\n",
      "8 10\n",
      "(1, 0, (5,))\n",
      "8 11\n",
      "(1, 0, (4,))\n",
      "8 12\n",
      "(1, 0, (3,))\n",
      "8 13\n",
      "(1, 0, (12,))\n",
      "8 14\n",
      "(1, 0, (14,))\n",
      "9 0\n",
      "(1, 0, (19,))\n",
      "9 1\n",
      "(1, 0, (9,))\n",
      "9 2\n",
      "(1, 0, (7,))\n",
      "9 3\n",
      "(1, 0, (7,))\n",
      "9 4\n",
      "(1, 0, (0,))\n",
      "9 5\n",
      "(1, 0, (0,))\n",
      "9 6\n",
      "(1, 0, (1,))\n",
      "9 7\n",
      "(1, 0, (4,))\n",
      "9 8\n",
      "(1, 0, (6,))\n",
      "9 9\n",
      "(1, 0, (5,))\n",
      "9 10\n",
      "(1, 0, (4,))\n",
      "9 11\n",
      "(1, 0, (1,))\n",
      "9 12\n",
      "(1, 0, (0,))\n",
      "9 13\n",
      "(1, 0, (10,))\n",
      "9 14\n",
      "(1, 0, (11,))\n",
      "10 0\n",
      "(1, 0, (21,))\n",
      "10 1\n",
      "(1, 0, (13,))\n",
      "10 2\n",
      "(1, 0, (8,))\n",
      "10 3\n",
      "(1, 0, (6,))\n",
      "10 4\n",
      "(1, 0, (0,))\n",
      "10 5\n",
      "(1, 0, (0,))\n",
      "10 6\n",
      "(1, 0, (0,))\n",
      "10 7\n",
      "(1, 0, (0,))\n",
      "10 8\n",
      "(1, 0, (1,))\n",
      "10 9\n",
      "(1, 0, (2,))\n",
      "10 10\n",
      "(1, 0, (0,))\n",
      "10 11\n",
      "(1, 0, (0,))\n",
      "10 12\n",
      "(1, 0, (0,))\n",
      "10 13\n",
      "(1, 0, (9,))\n",
      "10 14\n",
      "(1, 0, (9,))\n",
      "11 0\n",
      "(1, 0, (17,))\n",
      "11 1\n",
      "(1, 0, (12,))\n",
      "11 2\n",
      "(1, 0, (8,))\n",
      "11 3\n",
      "(1, 0, (12,))\n",
      "11 4\n",
      "(1, 0, (7,))\n",
      "11 5\n",
      "(1, 0, (0,))\n",
      "11 6\n",
      "(1, 0, (0,))\n",
      "11 7\n",
      "(1, 0, (0,))\n",
      "11 8\n",
      "(1, 0, (0,))\n",
      "11 9\n",
      "(1, 0, (0,))\n",
      "11 10\n",
      "(1, 0, (0,))\n",
      "11 11\n",
      "(1, 0, (0,))\n",
      "11 12\n",
      "(1, 0, (0,))\n",
      "11 13\n",
      "(1, 0, (1,))\n",
      "11 14\n",
      "(1, 0, (9,))\n",
      "12 0\n",
      "(1, 0, (8,))\n",
      "12 1\n",
      "(1, 0, (18,))\n",
      "12 2\n",
      "(1, 0, (13,))\n",
      "12 3\n",
      "(1, 0, (7,))\n",
      "12 4\n",
      "(1, 0, (13,))\n",
      "12 5\n",
      "(1, 0, (8,))\n",
      "12 6\n",
      "(1, 0, (0,))\n",
      "12 7\n",
      "(1, 0, (0,))\n",
      "12 8\n",
      "(1, 0, (0,))\n",
      "12 9\n",
      "(1, 0, (0,))\n",
      "12 10\n",
      "(1, 0, (0,))\n",
      "12 11\n",
      "(1, 0, (0,))\n",
      "12 12\n",
      "(1, 0, (0,))\n",
      "12 13\n",
      "(1, 0, (0,))\n",
      "12 14\n",
      "(1, 0, (10,))\n",
      "13 0\n",
      "(1, 0, (2,))\n",
      "13 1\n",
      "(1, 0, (12,))\n",
      "13 2\n",
      "(1, 0, (11,))\n",
      "13 3\n",
      "(1, 0, (7,))\n",
      "13 4\n",
      "(1, 0, (14,))\n",
      "13 5\n",
      "(1, 0, (15,))\n",
      "13 6\n",
      "(1, 0, (11,))\n",
      "13 7\n",
      "(1, 0, (0,))\n",
      "13 8\n",
      "(1, 0, (0,))\n",
      "13 9\n",
      "(1, 0, (0,))\n",
      "13 10\n",
      "(1, 0, (0,))\n",
      "13 11\n",
      "(1, 0, (0,))\n",
      "13 12\n",
      "(1, 0, (0,))\n",
      "13 13\n",
      "(1, 0, (0,))\n",
      "13 14\n",
      "(1, 0, (9,))\n",
      "14 0\n",
      "(1, 0, (0,))\n",
      "14 1\n",
      "(1, 0, (11,))\n",
      "14 2\n",
      "(1, 0, (18,))\n",
      "14 3\n",
      "(1, 0, (21,))\n",
      "14 4\n",
      "(1, 0, (24,))\n",
      "14 5\n",
      "(1, 0, (16,))\n",
      "14 6\n",
      "(1, 0, (12,))\n",
      "14 7\n",
      "(1, 0, (2,))\n",
      "14 8\n",
      "(1, 0, (0,))\n",
      "14 9\n",
      "(1, 0, (0,))\n",
      "14 10\n",
      "(1, 0, (0,))\n",
      "14 11\n",
      "(1, 0, (0,))\n",
      "14 12\n",
      "(1, 0, (0,))\n",
      "14 13\n",
      "(1, 0, (0,))\n",
      "14 14\n",
      "(1, 0, (0,))\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "target = [1.,0.,0.]\n",
    "for i, cs_0 in enumerate(csarray_0):\n",
    "    for j, cs_1 in enumerate(csarray_1):\n",
    "        target[1] = cs_0\n",
    "        target[2] = cs_1\n",
    "        print '{0} {1}'.format(i, j)\n",
    "        #print target\n",
    "\n",
    "        # Compute F1 couplings and cross sections\n",
    "        cs_b0 = all_couplings[i * npoints + j]\n",
    "        cross_section_b0 = all_cross_sections[i * npoints + j]  \n",
    "        map(lambda (var, val): var.set_value(val), zip(couplings[0],cs_b0))\n",
    "        map(lambda (var, val): var.set_value(val), zip(cross_sections[0],cross_section_b0))\n",
    "\n",
    "        cs_b1 = all_couplings[npoints * npoints + i * npoints + j]\n",
    "        cross_section_b1 = all_cross_sections[npoints * npoints + i * npoints + j]\n",
    "        map(lambda (var, val): var.set_value(val), zip(couplings[1],cs_b1))\n",
    "        map(lambda (var, val): var.set_value(val), zip(cross_sections[1],cross_section_b1))\n",
    "        # Compute ratios\n",
    "        ratio_0 = base_ratios[0]\n",
    "        ratio_1 = base_ratios[1]\n",
    "        # Compute weights for each ratio\n",
    "        w_0 = np.multiply(cs_b0, cross_section_b0)\n",
    "        \n",
    "        w_1 = np.multiply(cs_b1, cross_section_b1)\n",
    "        alpha_0, n_eff_0 = get_weights(w_0)\n",
    "        alpha_1, n_eff_1 = get_weights(w_1)\n",
    "\n",
    "        alphas[0,i,j] = alpha_0 / (alpha_0 + alpha_1)\n",
    "        alphas[1,i,j] = alpha_1 / (alpha_0 + alpha_1)\n",
    "        \n",
    "        n_effs[i,j] = alphas[0,i,j]*n_eff_0 + alphas[1,i,j]*n_eff_1\n",
    "        #print(n_effs[i,j])\n",
    "         \n",
    "        # Check ratios for negative of non defined values\n",
    "        r_0 = ratio_0.predict(X_observed)\n",
    "        r_1 = ratio_1.predict(X_observed)\n",
    "        z_0 = r_0[np.isinf(r_0)].shape[0]\n",
    "        z_1 = r_1[np.isinf(r_1)].shape[0]\n",
    "        #print(z_0,z_1)\n",
    "        r_0[np.isinf(r_0)] = 0. # Not sure about this\n",
    "        r_1[np.isinf(r_1)] = 0.\n",
    "        \n",
    "        # ratio weighting\n",
    "        ratio = alphas[0,i,j] * r_0 + alphas[1,i,j] * r_1\n",
    "        print(z_0,z_1,ratio[ratio <= 0.].shape)\n",
    "        ratio = ratio[ratio > 0.]\n",
    "        decomposedLikelihood[i,j] = -np.log(ratio).sum()\n",
    "        #print(decomposedLikelihood[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.mlab import griddata\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel as C, Matern\n",
    "\n",
    "theta = np.array([x for x in product(csarray_0, csarray_1)])\n",
    "llr = decomposedLikelihood.flatten()\n",
    "mle = np.argmin(llr)\n",
    "llr -= llr[mle]\n",
    "llr *= 2.\n",
    "gp = GaussianProcessRegressor(alpha=0.0, normalize_y=True, \n",
    "                              kernel=C(1.0) * Matern(1.0, length_scale_bounds=\"fixed\"))\n",
    "gp.fit(theta, llr)\n",
    "\n",
    "xi = np.linspace(-0.6, 0.6, 500)\n",
    "yi = np.linspace(-0.6, 0.6, 500)\n",
    "    \n",
    "xx, yy = np.meshgrid(xi, yi)\n",
    "zz, std = gp.predict(np.c_[xx.ravel(), yy.ravel()], return_std=True)\n",
    "zi = zz.reshape(xx.shape)\n",
    "\n",
    "cs = plt.contour(xi, yi, zi, 30, linewidths=0.5, colors='w')\n",
    "cs = plt.contourf(xi, yi, zi, 30, cmap=\"viridis\",\n",
    "                  vmax=abs(zi).max(), vmin=0.0)\n",
    "plt.colorbar()  \n",
    "#plt.scatter(theta[:, 0], theta[:, 1], marker='o', c='b', s=50, lw=0, zorder=10)\n",
    "plt.scatter([theta[mle, 0]], [theta[mle, 1]], marker='o', c='r', s=50, lw=0, zorder=10)\n",
    "plt.scatter([F1[1]], [F1[2]], marker='o', c='w', s=50, lw=0, zorder=10)\n",
    "plt.xlim(-0.6, 0.6)\n",
    "plt.ylim(-0.6, 0.6)\n",
    "plt.xlabel(\"KHzz\")\n",
    "plt.ylabel(\"kAzz\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found arrays with inconsistent numbers of samples: [29 30]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2c32818d24d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m gp = GaussianProcessRegressor(alpha=0.0, normalize_y=True, \n\u001b[0;32m     10\u001b[0m                               kernel=C(1.0) * Matern(1.0, length_scale_bounds=\"fixed\"))\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mllr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mxi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/cern.ch/user/j/jpavezse/.local/lib/python2.7/site-packages/sklearn/gaussian_process/gpr.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrng\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m# Normalize target value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/cern.ch/user/j/jpavezse/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/afs/cern.ch/user/j/jpavezse/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         raise ValueError(\"Found arrays with inconsistent numbers of samples: \"\n\u001b[1;32m--> 180\u001b[1;33m                          \"%s\" % str(uniques))\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found arrays with inconsistent numbers of samples: [29 30]"
     ]
    }
   ],
   "source": [
    "theta = np.array([x for x in product(csarray_0, csarray_1)])\n",
    "llr = n_effs.flatten()\n",
    "gp = GaussianProcessRegressor(alpha=0.0, normalize_y=True, \n",
    "                              kernel=C(1.0) * Matern(1.0, length_scale_bounds=\"fixed\"))\n",
    "gp.fit(theta, llr)\n",
    "\n",
    "xi = np.linspace(-0.6, 0.6, 500)\n",
    "yi = np.linspace(-0.6, 0.6, 500)\n",
    "    \n",
    "xx, yy = np.meshgrid(xi, yi)\n",
    "zz, std = gp.predict(np.c_[xx.ravel(), yy.ravel()], return_std=True)\n",
    "zi = zz.reshape(xx.shape)\n",
    "\n",
    "cs = plt.contour(xi, yi, zi, 30, linewidths=0.5, colors='w')\n",
    "cs = plt.contourf(xi, yi, zi, 30, cmap=\"viridis\",\n",
    "                  vmax=abs(zi).max(), vmin=0.0)\n",
    "plt.colorbar()  \n",
    "#plt.scatter(theta[:, 0], theta[:, 1], marker='o', c='b', s=50, lw=0, zorder=10)\n",
    "plt.scatter([F1[1]], [F1[2]], marker='o', c='w', s=50, lw=0, zorder=10)\n",
    "plt.xlim(-0.6, 0.6)\n",
    "plt.ylim(-0.6, 0.6)\n",
    "plt.xlabel(\"KHzz\")\n",
    "plt.ylabel(\"kAzz\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
